{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "project-header",
   "metadata": {},
   "source": [
    "# âš¡ Chess Analysis Pipeline - Data Decompression\n",
    "\n",
    "## Overview\n",
    "This notebook handles the decompression of Zstandard (.zst) compressed chess game files from the Lichess database. The decompression process is optimized for large files with real-time progress tracking and error handling.\n",
    "\n",
    "### ðŸ”§ Technical Specifications\n",
    "- **Input Format**: `.pgn.zst` (PGN files compressed with Zstandard)\n",
    "- **Output Format**: `.pgn` (Plain text Portable Game Notation)\n",
    "- **Compression Ratio**: Typically 10:1 to 15:1 for chess data\n",
    "- **Memory Usage**: Stream-based processing (16MB chunks)\n",
    "\n",
    "### ðŸ“ˆ Performance Features\n",
    "- **Streaming Decompression**: Processes data in chunks to minimize memory usage\n",
    "- **Real-time Monitoring**: Live progress tracking with speed metrics\n",
    "- **Error Recovery**: Graceful handling of interruptions with cleanup\n",
    "- **Size Validation**: Tracks both compressed and decompressed sizes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Required Dependencies\n",
    "\n",
    "Setting up the decompression environment with Zstandard support and progress visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e8bff-c4b8-4406-96d3-dc443c0f1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard as zst\n",
    "import os\n",
    "from rich.progress import (\n",
    "    Progress,\n",
    "    BarColumn,\n",
    "    TextColumn,\n",
    "    DownloadColumn,\n",
    "    TransferSpeedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-functions",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Utility Functions\n",
    "\n",
    "### File Size Formatting\n",
    "The `format_size()` function converts raw byte counts into human-readable format using binary units (KiB, MiB, GiB) for accurate file size representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8fad5-5242-4c90-b8da-2014c1ef02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_size(byte_count):\n",
    "    power = 1024\n",
    "    n = 0\n",
    "    power_labels = {0: 'B', 1: 'KiB', 2: 'MiB', 3: 'GiB', 4: 'TiB'}\n",
    "    while byte_count >= power and n < len(power_labels) - 1:\n",
    "        byte_count /= power\n",
    "        n += 1\n",
    "    return f\"{byte_count:.2f} {power_labels[n]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decompression-section",
   "metadata": {},
   "source": [
    "## ðŸ—œï¸ Zstandard Decompression Process\n",
    "\n",
    "### Why Zstandard?\n",
    "Zstandard (.zst) is chosen for chess databases because:\n",
    "- **Superior Compression**: 15-30% better than gzip for text data\n",
    "- **Fast Decompression**: High-speed streaming decompression\n",
    "- **Memory Efficient**: Stream-based processing without loading entire file\n",
    "\n",
    "### Process Flow\n",
    "1. **File Validation**: Checks if compressed file exists\n",
    "2. **Stream Setup**: Creates decompression stream with 16MB chunks\n",
    "3. **Progress Tracking**: Real-time monitoring of decompression progress\n",
    "4. **Output Generation**: Writes decompressed PGN data to output file\n",
    "5. **Cleanup**: Handles interruptions and errors gracefully\n",
    "\n",
    "### Expected Results\n",
    "- **Input**: ~1.0 GB compressed file\n",
    "- **Output**: ~7-10 GB decompressed PGN file\n",
    "- **Processing Time**: 2-5 minutes depending on system\n",
    "\n",
    "> **Note**: The decompression will show both input progress and output size growth in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612699d3-192d-43f1-a494-abc888d32f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_file = \"lichess_db_standard_rated_2025-08.pgn.zst\"\n",
    "decompressed_file = \"lichess_db_standard_rated_2025-08.pgn\"\n",
    "\n",
    "if not os.path.exists(compressed_file):\n",
    "    print(f\"Ã¢Å’ Error: Input file not found at '{compressed_file}'\")\n",
    "else:\n",
    "    total_size = os.path.getsize(compressed_file)\n",
    "\n",
    "    progress = Progress(\n",
    "        TextColumn(\"[bold cyan]{task.fields[filename]}\", justify=\"right\"),\n",
    "        BarColumn(bar_width=None),\n",
    "        \"[progress.percentage]{task.percentage:>3.1f}%\",\n",
    "        \"Ã¢â‚¬Â¢\",\n",
    "        DownloadColumn(binary_units=True),\n",
    "        \"Ã¢â‚¬Â¢\",\n",
    "        TransferSpeedColumn(),\n",
    "        \"Ã¢â‚¬Â¢\",\n",
    "        TimeRemainingColumn(),\n",
    "        \"Ã¢â‚¬Â¢\",\n",
    "        TextColumn(\"[green]Output Size: {task.fields[out_size]}\")\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with open(compressed_file, 'rb') as f_in:\n",
    "            with open(decompressed_file, 'wb') as f_out:\n",
    "                dctx = zst.ZstdDecompressor()\n",
    "                reader = dctx.stream_reader(f_in)\n",
    "                \n",
    "                with progress:\n",
    "                    task_id = progress.add_task(\n",
    "                        \"Decompressing\",\n",
    "                        filename=os.path.basename(compressed_file),\n",
    "                        total=total_size,\n",
    "                        out_size=\"0 B\"\n",
    "                    )\n",
    "                    \n",
    "                    decompressed_bytes_so_far = 0\n",
    "                    \n",
    "                    while True:\n",
    "                        chunk = reader.read(16 * 1024 * 1024)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        \n",
    "                        f_out.write(chunk)\n",
    "                        decompressed_bytes_so_far += len(chunk)\n",
    "                        \n",
    "                        progress.update(\n",
    "                            task_id,\n",
    "                            completed=f_in.tell(),\n",
    "                            out_size=format_size(decompressed_bytes_so_far)\n",
    "                        )\n",
    "\n",
    "        progress.update(task_id, completed=total_size)\n",
    "        print(f\"\\nÃ¢Å“â€¦ Decompression complete! Final size: {format_size(decompressed_bytes_so_far)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nÃ¢Å’ Error: The file '{compressed_file}' was not found.\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nÃ¢Â¹Ã¯Â¸ Decompression interrupted by user. Cleaning up...\")\n",
    "        if os.path.exists(decompressed_file):\n",
    "            os.remove(decompressed_file)\n",
    "            print(\"Ã°Å¸Â§Â¹ Partial file removed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-section",
   "metadata": {},
   "source": [
    "## ðŸ“Š Decompression Results & Next Steps\n",
    "\n",
    "### Expected Output\n",
    "After successful decompression, you should have:\n",
    "- **File Size**: 7-10 GB of uncompressed PGN data\n",
    "- **Game Count**: Approximately 200,000-300,000 chess games\n",
    "- **Format**: Standard PGN with complete game metadata\n",
    "\n",
    "### Data Structure Preview\n",
    "The decompressed PGN file contains chess games in this format:\n",
    "```\n",
    "[Event \"Rated Blitz game\"]\n",
    "[Site \"https://lichess.org/abc123\"]\n",
    "[Date \"2025.08.01\"]\n",
    "[White \"Player1\"]\n",
    "[Black \"Player2\"]\n",
    "[Result \"1-0\"]\n",
    "[WhiteElo \"1500\"]\n",
    "[BlackElo \"1600\"]\n",
    "[TimeControl \"180+2\"]\n",
    "[ECO \"B10\"]\n",
    "[Opening \"Caro-Kann Defense\"]\n",
    "[Termination \"Normal\"]\n",
    "\n",
    "1. e4 c6 2. d4 d5 3. Nc3 dxe4...\n",
    "```\n",
    "\n",
    "### ðŸ”„ Pipeline Continuation\n",
    "The next notebook (`03_data_processing.ipynb`) will:\n",
    "1. **Parse PGN Format**: Convert text data into structured DataFrame\n",
    "2. **Data Cleaning**: Handle malformed records and missing fields\n",
    "3. **Spark Integration**: Load data into distributed processing framework\n",
    "4. **Schema Validation**: Ensure data quality for downstream analysis\n",
    "\n",
    "### ðŸ’¾ Storage Considerations\n",
    "- **Disk Space**: Ensure at least 15 GB free space for processing\n",
    "- **Temporary Files**: Decompression creates intermediate files\n",
    "- **Backup Strategy**: Consider keeping compressed version for recovery\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Success Metrics\n",
    "- **Compression Ratio**: ~10:1 (1 GB â†’ 10 GB typical)\n",
    "- **Processing Speed**: 50-200 MB/s decompression rate\n",
    "- **Data Integrity**: Zero data loss during decompression\n",
    "- **Error Handling**: Graceful recovery from interruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64d4ed-6bfb-44fe-b856-23469266cb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_env)",
   "language": "python",
   "name": "spark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}